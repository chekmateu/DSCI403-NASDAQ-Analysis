{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c3e05-1d84-482f-88a7-4517c006c862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "import zipfile\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732ba47-43b2-40ae-8bbd-895fef347ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    with zipfile.ZipFile('archive.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    os.remove('archive.zip')\n",
    "else:\n",
    "    print('Exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04f118-09f6-4e7b-95e4-d9ee00a5458b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NASDAQ_Data():\n",
    "    def __init__(self, time_range = ['2010-1-1', '2020-1-1']):\n",
    "        self.etf_files = glob.glob('data/etfs/*.csv')\n",
    "        self.stock_files = glob.glob('data/stocks/*.csv')\n",
    "        self.time_range = time_range\n",
    "\n",
    "    def get_meta(self):\n",
    "        return pd.read_csv('data/symbols_valid_meta.csv')\n",
    "    \n",
    "    def get_ticker(self, ticker):\n",
    "\n",
    "        def calculate_rsi(prices, period=14):\n",
    "            delta = prices.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "            avg_gain = gain.ewm(com=period - 1, min_periods=period).mean()\n",
    "            avg_loss = loss.ewm(com=period - 1, min_periods=period).mean()\n",
    "\n",
    "            rs = avg_gain / avg_loss\n",
    "            rsi = 100 - (100 / (1 + rs))\n",
    "            return rsi\n",
    "        \n",
    "        def calculate_logReturns(prices):\n",
    "            return np.log(prices, where = prices > 0) - np.log(prices.shift(1), where = prices > 0)\n",
    "        \n",
    "        def mfi(high, low, close, volume, n=14):\n",
    "            typical_price = (high + low + close) / 3\n",
    "            money_flow = typical_price * volume\n",
    "            mf_sign = np.where(typical_price > typical_price.shift(1), 1, -1)\n",
    "            signed_mf = money_flow * mf_sign\n",
    "\n",
    "            # Calculate gain and loss using vectorized operations\n",
    "            positive_mf = np.where(signed_mf > 0, signed_mf, 0)\n",
    "            negative_mf = np.where(signed_mf < 0, -signed_mf, 0)\n",
    "\n",
    "            mf_avg_gain = pd.Series(positive_mf).rolling(n, min_periods=1).sum()\n",
    "            mf_avg_loss = pd.Series(negative_mf).rolling(n, min_periods=1).sum()\n",
    "\n",
    "            return (100 - 100 / (1 + mf_avg_gain / mf_avg_loss)).to_numpy()\n",
    "        \n",
    "        def atr(high, low, close, n=14):\n",
    "            tr = np.amax(np.vstack(((high - low).to_numpy(), (abs(high - close)).to_numpy(), (abs(low - close)).to_numpy())).T, axis=1)\n",
    "            return pd.Series(tr).rolling(n).mean().to_numpy()\n",
    "\n",
    "        def EMV(data, ndays): \n",
    "            dm = ((data['High'] + data['Low'])/2) - ((data['High'].shift(1) + data['Low'].shift(1))/2)\n",
    "            br = (data['Volume'] / 100000000) / ((data['High'] - data['Low']))\n",
    "            EMV = dm / br \n",
    "            EMV_MA = pd.Series(EMV.rolling(ndays).mean(), name = 'EMV') \n",
    "            return EMV_MA\n",
    "        \n",
    "        if f\"data/etfs/{ticker}.csv\" in self.etf_files:\n",
    "            df = pd.read_csv(f\"data/etfs/{ticker}.csv\").drop(columns = ['Adj Close'])\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format = \"%Y-%m-%d\")\n",
    "            df = df.set_index('Date')\n",
    "        elif f\"data/stocks/{ticker}.csv\" in self.stock_files:\n",
    "            df = pd.read_csv(f\"data/stocks/{ticker}.csv\").drop(columns = ['Adj Close'])\n",
    "            df['Date'] = pd.to_datetime(df['Date'], format = \"%Y-%m-%d\")\n",
    "            df = df.set_index('Date')\n",
    "        else:\n",
    "            print(f'{ticker} not found')\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Introduce normalized features\n",
    "        df.insert(len(df.columns), \"RSI14\", calculate_rsi(df.Close, period = 14), True)\n",
    "        df.insert(len(df.columns), \"Log_ret\", calculate_logReturns(df.Close), True)\n",
    "        df.insert(len(df.columns), \"MFI14\", mfi(df.High, df.Low, df.Close, df.Volume, n = 14), True)\n",
    "        df.insert(len(df.columns), \"ATR14\", atr(df.High, df.Low, df.Close, n = 14), True)\n",
    "        df.insert(len(df.columns), \"EMV14\", EMV(df, ndays = 14), True)\n",
    "\n",
    "        if ( # check if 30 days before the minimum time_range exists\n",
    "            len(df[pd.to_datetime(self.time_range[0], format = \"%Y-%m-%d\") - pd.Timedelta(30, \"d\") : pd.to_datetime(self.time_range[0], format = \"%Y-%m-%d\")]) != 0\n",
    "            ):\n",
    "            return df[\n",
    "                pd.to_datetime(self.time_range[0], format = \"%Y-%m-%d\") : pd.to_datetime(self.time_range[1], format = \"%Y-%m-%d\")\n",
    "            ]\n",
    "        else:\n",
    "            print(f\"{ticker} : Doesn't exist before {self.time_range[0]}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def create_dataset(self, filename):\n",
    "        np.seterr(divide = 'ignore') \n",
    "\n",
    "        threshold = 0.05\n",
    "        \n",
    "        def rolling_window(arr, w_size, spacing):\n",
    "            return [arr[i: i+w_size] for i in range(0, arr.shape[0] - w_size, spacing)]\n",
    "\n",
    "        fileh = tb.open_file(filename, mode = 'w')\n",
    "        hdf5_Features = fileh.create_earray(\n",
    "            fileh.root,\n",
    "            'Features',\n",
    "            tb.Float64Atom(shape=()),\n",
    "            (0, 200, 5),\n",
    "            title = \"Features\",\n",
    "            )\n",
    "        \n",
    "        hdf5_Labels = fileh.create_earray(\n",
    "            fileh.root,\n",
    "            'Labels',\n",
    "            tb.Int8Atom(shape=()),\n",
    "            (0, 3),\n",
    "            title = \"Labels\",\n",
    "            )\n",
    "        \n",
    "        symbols = self.get_meta().Symbol\n",
    "        totals = [0, 0, 0]\n",
    "        processed = 0\n",
    "        invalid_symbols = []\n",
    "        for symbol in symbols:\n",
    "            processed += 1\n",
    "            print(f'{processed}/{len(symbols)} : {symbol}')\n",
    "            \n",
    "            counts = [0, 0, 0]\n",
    "            features = [] # shape = (# samples, 200 days, n features)\n",
    "            target = [] # shape  = (# samples, label) label = [1, 0, 0]; [0, 1, 0]; [0, 0, 1]\n",
    "\n",
    "            ticker = self.get_ticker(symbol)\n",
    "            if not ticker.empty:\n",
    "                data = rolling_window(ticker.to_numpy(), 210, 5) # shape = (# samples, 210 days, 5 features)\n",
    "            else:\n",
    "                invalid_symbols.append(symbol)\n",
    "                continue\n",
    "            \n",
    "            for sample in data:\n",
    "                future_10 = sample[-10:]\n",
    "                prior_200 = sample[:200]\n",
    "                last_day = prior_200[-1][3]\n",
    "                if np.average(future_10[:, 3]) >= last_day + (threshold * last_day): # did it go up by a threshold?\n",
    "                    target.append([0, 0, 1])\n",
    "                    counts[2] += 1\n",
    "                elif np.average(future_10[:, 3]) <= last_day - (threshold * last_day): # did it go down by a threshold?\n",
    "                    target.append([1, 0, 0])\n",
    "                    counts[0] += 1\n",
    "                else:\n",
    "                    target.append([0, 1, 0])\n",
    "                    counts[1] += 1\n",
    "\n",
    "                features.append(prior_200[:, [5, 6, 7, 8, 9]]) # keep only the TA indicators \n",
    "    \n",
    "            # Balance Data\n",
    "            balanced_features = []\n",
    "            balanced_labels = []\n",
    "            max_class = min(counts)\n",
    "            if max_class == 0:\n",
    "                # Scrap the entry\n",
    "                invalid_symbols.append(symbol)\n",
    "                print(f\"{symbol} : Empty Class Present\")\n",
    "                continue\n",
    "\n",
    "            for i in range(3):\n",
    "                count = 0\n",
    "                for data, lab in zip(features, target):\n",
    "                    if lab.index(1) == i:\n",
    "                        balanced_features.append(data)\n",
    "                        balanced_labels.append(lab)\n",
    "                        count += 1\n",
    "                    if count == max_class:\n",
    "                        break\n",
    "                totals[i] += count\n",
    "\n",
    "            hdf5_Features.append(np.array(balanced_features))\n",
    "            hdf5_Labels.append(np.array(balanced_labels))\n",
    "\n",
    "        fileh.close()\n",
    "        print(f'Class Totals : {totals}')\n",
    "        print(\"Didn't Pricess - \")\n",
    "        print(invalid_symbols)\n",
    "        np.seterr(divide = 'warn') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27560fb-62c0-4d68-ac98-1c49d37f1de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = NASDAQ_Data()\n",
    "# aapl = data.get_ticker('AAPL')\n",
    "# nvda = data.get_ticker('NVDA')\n",
    "data.create_dataset(filename = 'data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    print(\"Keys: %s\" % f.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
